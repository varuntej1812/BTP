{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581313dc",
   "metadata": {},
   "source": [
    "Number of Reviews posted by each user on a particular date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "807a7ee5-5966-40d0-8f47-2bdeb0a78132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id       date  num_reviews\n",
      "0      ---2PmXbF47D870stH1jqA 2014-07-10            1\n",
      "1      ---2PmXbF47D870stH1jqA 2014-10-28            1\n",
      "2      ---2PmXbF47D870stH1jqA 2015-06-27            1\n",
      "3      --3WaS23LcIXtxyFULJHTA 2015-10-02            1\n",
      "4      --6PFZka7og6Khaw6oyjvQ 2015-05-30            1\n",
      "...                       ...        ...          ...\n",
      "95681  zziJLt25YU6dp01sewR-IQ 2010-11-25            1\n",
      "95682  zziJLt25YU6dp01sewR-IQ 2012-02-10            1\n",
      "95683  zziJLt25YU6dp01sewR-IQ 2012-10-29            1\n",
      "95684  zziJLt25YU6dp01sewR-IQ 2012-11-01            1\n",
      "95685  zziJLt25YU6dp01sewR-IQ 2012-11-04            1\n",
      "\n",
      "[95686 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('btp.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "user_date_review_counts = df.groupby(['user_id', 'date'])['review_id'].count().reset_index()\n",
    "user_date_review_counts.columns = ['user_id', 'date', 'num_reviews']\n",
    "print(user_date_review_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "491fe2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id       date  num_reviews\n",
      "8080   4F59l8scDgg6BQx0HGRtcQ 2015-01-03            6\n",
      "14484  8O5tGAz_LFuX3JTim7Egyg 2011-03-03            8\n",
      "14528  8RcEwGrFIgkt9WQ35E6SnQ 2016-08-19            9\n",
      "17483  AW2cimP0kAlKiNs4iEwa7A 2013-02-22            6\n",
      "19717  BrH27yHhgDEylDZfFdJvSQ 2009-03-28            6\n",
      "20902  Cf8Jw9yX8RrG-l4PQoMkuw 2012-02-26            8\n",
      "28347  Hn8O2RQijYIVLFNF5VPWTA 2011-01-04           10\n",
      "34220  LlLNWV5FmKvjOj0p5qGYeg 2010-05-23            6\n",
      "36539  NUtIAX-ygn474tDg5nmesg 2015-02-16            7\n",
      "39465  PUj5BTAscm67FZQkqe2qwQ 2015-09-13            6\n",
      "53928  YzckMAdpT00nnHutGtTWEQ 2014-02-05            7\n",
      "55490  _4Wn2zRkrmDfowBrNcji0Q 2013-06-02            6\n",
      "58246  amIUTkKQlA4464-lJlwlaQ 2013-03-20            6\n",
      "58917  bJQgJdeqvE7njsTZomhaoQ 2016-07-12            6\n",
      "76121  n-lBS02-3yvlY5Q91mmwDA 2005-07-10           11\n",
      "77340  nnwBdqGHIAJQ5QX9lHOtrQ 2009-01-27            9\n",
      "84158  sLqm9fRo_u81kJCIRdzrMg 2008-05-24           11\n",
      "87278  uZzs_KFzSDFjpyVLyl7Pqg 2010-06-29            8\n",
      "92058  xjQSpme1Z7Xw8XehRLpYuA 2012-06-26            6\n",
      "94000  yyxEa8y4HGij_m7g1wDKWg 2015-04-10            6\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "user_date_review_counts = df.groupby(['user_id', 'date'])['review_id'].count().reset_index()\n",
    "user_date_review_counts.columns = ['user_id', 'date', 'num_reviews']\n",
    "users_with_more_than_5_reviews = user_date_review_counts[user_date_review_counts['num_reviews'] > 5]\n",
    "print(users_with_more_than_5_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962c8a3",
   "metadata": {},
   "source": [
    "Total Reviews on each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29c6a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       2\n",
      "2       1\n",
      "3       1\n",
      "4       2\n",
      "       ..\n",
      "5430    1\n",
      "5431    1\n",
      "5432    1\n",
      "5433    1\n",
      "5434    1\n",
      "Name: total_reviews, Length: 5435, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filtered_reviews = total_reviews_by_date['total_reviews']\n",
    "\n",
    "# Display the result\n",
    "print(filtered_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18192ea8",
   "metadata": {},
   "source": [
    "Less than 60 seconds time difference reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb7dd66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_8028\\2336372979.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['time'] = pd.to_datetime(df['time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id       date  num_reviews\n",
      "36     -0vutwuE36iYMqM2wHaStQ 2009-03-12            2\n",
      "41     -13RX4Gy_F-zoLIenWAo-w 2007-04-20            2\n",
      "45     -2TJaAdxSGnTyy9qGr1z1Q 2011-04-08            2\n",
      "49     -2Vg22LqKpg0zjf5A-SWLA 2015-01-23            2\n",
      "62     -2nNiAnDaSbQayynsqgL6Q 2011-09-20            2\n",
      "...                       ...        ...          ...\n",
      "95614  zwPKdviIT_C4CD2ZL_nJyQ 2012-06-19            2\n",
      "95621  zx4c7K-1eBSvEmUg7zqiZQ 2011-03-09            2\n",
      "95631  zxeXnjqmlrAspfk17LSZCg 2011-03-20            3\n",
      "95639  zxuxd6Hz2tKcpgZ71dYEcw 2014-04-03            2\n",
      "95654  zyNrXvJyYdC34tS6BcCykA 2009-11-17            3\n",
      "\n",
      "[6503 rows x 3 columns]\n",
      "                      user_id       date       time_diff\n",
      "43095  -NMGRUbMdKZ7acHGWKvy8Q 2010-09-07 0 days 00:00:34\n",
      "90140  -hq6dkvt907T0MPJK9Qaig 2013-04-16 0 days 00:00:29\n",
      "96233  0Cl_C3VvG88g-Hussui3_Q 2014-06-28 0 days 00:00:32\n",
      "28479  0EQlpgEQVTxCeKd7CbetdQ 2010-12-15 0 days 00:00:59\n",
      "27996  0d1Qa6dckkZ9UTK_1_eNTw 2012-10-14 0 days 00:00:42\n",
      "...                       ...        ...             ...\n",
      "88667  xl2Lspp8Ltqy_qTVMNja_g 2011-01-06 0 days 00:00:45\n",
      "14639  xyFtRXaTjhStZB3Zb9uFvA 2008-01-16 0 days 00:00:52\n",
      "18950  yoa61s3IdHwi8q5_gLvzaw 2012-10-25 0 days 00:00:51\n",
      "28270  yx8wkvWdCH-eN6PHWKT7Wg 2014-02-19 0 days 00:00:55\n",
      "62539  zxeXnjqmlrAspfk17LSZCg 2011-03-20 0 days 00:00:54\n",
      "\n",
      "[148 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.sort_values(by=['user_id', 'date', 'time'], inplace=True)\n",
    "df['time_diff'] = df.groupby(['user_id', 'date'])['time'].diff()\n",
    "user_date_review_counts = df.groupby(['user_id', 'date'])['review_id'].count().reset_index()\n",
    "user_date_review_counts.columns = ['user_id', 'date', 'num_reviews']\n",
    "users_with_more_than_1_review = user_date_review_counts[user_date_review_counts['num_reviews'] > 1]\n",
    "print(users_with_more_than_1_review[['user_id', 'date', 'num_reviews']])\n",
    "filtered_rows = df.loc[(df['user_id'].isin(users_with_more_than_1_review['user_id'])) & (df['time_diff'] < pd.Timedelta('60 seconds'))]\n",
    "print(filtered_rows[['user_id', 'date', 'time_diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c5d1f",
   "metadata": {},
   "source": [
    "Less than 5 seconds time differnce reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebb0e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id       date  num_reviews\n",
      "36     -0vutwuE36iYMqM2wHaStQ 2009-03-12            2\n",
      "41     -13RX4Gy_F-zoLIenWAo-w 2007-04-20            2\n",
      "45     -2TJaAdxSGnTyy9qGr1z1Q 2011-04-08            2\n",
      "49     -2Vg22LqKpg0zjf5A-SWLA 2015-01-23            2\n",
      "62     -2nNiAnDaSbQayynsqgL6Q 2011-09-20            2\n",
      "...                       ...        ...          ...\n",
      "95614  zwPKdviIT_C4CD2ZL_nJyQ 2012-06-19            2\n",
      "95621  zx4c7K-1eBSvEmUg7zqiZQ 2011-03-09            2\n",
      "95631  zxeXnjqmlrAspfk17LSZCg 2011-03-20            3\n",
      "95639  zxuxd6Hz2tKcpgZ71dYEcw 2014-04-03            2\n",
      "95654  zyNrXvJyYdC34tS6BcCykA 2009-11-17            3\n",
      "\n",
      "[6503 rows x 3 columns]\n",
      "                      user_id       date       time_diff\n",
      "80156  FjOKTsuKtdoLhz3CWsuEPQ 2012-02-01 0 days 00:00:00\n",
      "80859  O8v43MR97f2vz_v2br8mNg 2011-01-30 0 days 00:00:01\n",
      "85684  WJpWp-3zZ3iuwEYCGGf0yA 2012-03-15 0 days 00:00:00\n",
      "56117  YEiJOtOBBRKEpRuvZNA9Cg 2011-07-11 0 days 00:00:01\n",
      "77914  cKRiEclULFf4TczO1-tf3A 2012-06-18 0 days 00:00:01\n",
      "79976  d8FwfuFM9SJA3kU_cIQ3aw 2015-05-17 0 days 00:00:04\n",
      "27330  esMNMMH7BKkiJd91fvO-FA 2011-08-16 0 days 00:00:03\n",
      "65556  u8tyDjEaANLSOZ4MTKfhhg 2012-07-06 0 days 00:00:01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.sort_values(by=['user_id', 'date', 'time'], inplace=True)\n",
    "df['time_diff'] = df.groupby(['user_id', 'date'])['time'].diff()\n",
    "user_date_review_counts = df.groupby(['user_id', 'date'])['review_id'].count().reset_index()\n",
    "user_date_review_counts.columns = ['user_id', 'date', 'num_reviews']\n",
    "users_with_more_than_1_review = user_date_review_counts[user_date_review_counts['num_reviews'] > 1]\n",
    "print(users_with_more_than_1_review[['user_id', 'date', 'num_reviews']])\n",
    "filtered_rows = df.loc[(df['user_id'].isin(users_with_more_than_1_review['user_id'])) & (df['time_diff'] < pd.Timedelta('5 seconds'))]\n",
    "print(filtered_rows[['user_id', 'date', 'time_diff']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06e80af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'user_id', 'name', 'review_count', 'useful', 'review_id',\n",
      "       'stars', 'useful_review', 'text', 'date', 'time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "attributes = df.columns\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b58287",
   "metadata": {},
   "source": [
    "Star Rating Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b35c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_length'] = df['text'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
=======
   "id": "bd662779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id  average_stars  num_reviews\n",
      "5      --U6F4iI3ABK6IVCCgYc-g       2.500000            2\n",
      "8      --bcBB892GN4ycJbGli0MQ       2.000000            1\n",
      "9      --ccVMj2PN6Z9qtdOdlung       2.000000            2\n",
      "19     -0aZWYi2YicFaLxTru96nA       2.000000            1\n",
      "34     -2ccuXJJIQmaXKQ9krmRfw       2.000000            2\n",
      "...                       ...            ...          ...\n",
      "38239  zwIhFlA84tTLvSSjHc6IgA       2.714286           14\n",
      "38248  zxdgI8d0g6cX4mAl5_ALFA       1.666667            3\n",
      "38259  zywyfATfP8SPY8JaYBraIg       1.666667            3\n",
      "38261  zz0xCxZhHIceqSIlKIcj9A       2.000000            1\n",
      "38266  zzT0pSbiaNAPL171kwnvjA       1.000000            1\n",
      "\n",
      "[4945 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "# Calculate average star rating for each user\n",
    "user_avg_rating = df.groupby('user_id')['stars'].mean().reset_index()\n",
    "user_avg_rating.columns = ['user_id', 'average_stars']  # Rename the column for clarity\n",
    "\n",
    "# Count number of reviews made by each user\n",
    "user_review_count = df['user_id'].value_counts().reset_index()\n",
    "user_review_count.columns = ['user_id', 'num_reviews']\n",
    "\n",
    "# Merge average rating and review count DataFrames\n",
    "user_stats = pd.merge(user_avg_rating, user_review_count, on='user_id')\n",
    "\n",
    "# Filter users with average rating less than 3 and at least one review\n",
    "users_with_low_rating = user_stats[(user_stats['average_stars'] < 3) & (user_stats['num_reviews'] > 0)]\n",
    "\n",
    "# Display the result\n",
    "print(users_with_low_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
>>>>>>> d7b66802502eb6a7ef89693cafafc747e918c711
   "id": "808610f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Collecting spacy\n",
      "  Downloading spacy-3.7.4-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.3-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "     ---------------------------------------- 0.0/84.4 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 41.0/84.4 kB 991.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 81.9/84.4 kB 919.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 84.4/84.4 kB 680.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting setuptools (from spacy)\n",
      "  Using cached setuptools-69.1.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.26.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.16.3-cp312-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Downloading spacy-3.7.4-cp312-cp312-win_amd64.whl (11.7 MB)\n",
      "   ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.7 MB 3.3 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.3/11.7 MB 2.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/11.7 MB 2.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/11.7 MB 2.8 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/11.7 MB 2.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/11.7 MB 2.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.9/11.7 MB 2.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.1/11.7 MB 2.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.1/11.7 MB 2.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.2/11.7 MB 2.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.4/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.7/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.9/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.2/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.3/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.6/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.7/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.8/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.9/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.0/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.1/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.2/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.5/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.6/11.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.7/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.9/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.0/11.7 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/11.7 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.3/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.4/11.7 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.5/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.7/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.8/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.8/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.0/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.0/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.2/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.3/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.4/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.5/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.7/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.8/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.9/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.1/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.2/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.3/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.5/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.5/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.6/11.7 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.7/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.0/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.2/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.4/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.5/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.7/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.7/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.9/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.0/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.1/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.3/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.4/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.5/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.7/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.8/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.9/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.0/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.1/11.7 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.3/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.5/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.8/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.1/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.6/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.9/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.2/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.4/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.7/11.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.7/11.7 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 122.9/181.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 181.6/181.6 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.4 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 112.6/122.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 122.4/122.4 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "   ---------------------------------------- 0.0/395.2 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 245.8/395.2 kB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 358.4/395.2 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  389.1/395.2 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 395.2/395.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.16.3-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.9 MB 3.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/1.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.2/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.9 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 51.2/57.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.0/57.0 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl (478 kB)\n",
      "   ---------------------------------------- 0.0/478.8 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 245.8/478.8 kB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 276.5/478.8 kB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 440.3/478.8 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  471.0/478.8 kB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 478.8/478.8 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.4 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.6/1.4 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.9/45.9 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 1.3 MB/s eta 0:00:00\n",
      "Using cached setuptools-69.1.1-py3-none-any.whl (819 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading blis-0.7.11-cp312-cp312-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/6.6 MB 14.1 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.4/6.6 MB 4.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.5/6.6 MB 3.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.6/6.6 MB 3.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.7/6.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.7/6.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.8/6.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.0/6.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.1/6.6 MB 2.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.2/6.6 MB 2.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.3/6.6 MB 2.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.4/6.6 MB 2.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.5/6.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.7/6.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.8/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.9/6.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.0/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.2/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.3/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.4/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.5/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.5/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.7/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.8/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.0/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.3/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.4/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.4/6.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.5/6.6 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.6/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.7/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.9/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.0/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.1/6.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.2/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.4/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.6/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.8/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.9/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.0/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.1/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.3/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.4/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.7/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.9/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.9/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.4/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, setuptools, pydantic-core, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.6.3 pydantic-core-2.16.3 setuptools-69.1.1 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
=======
      "                      user_id  average_stars  num_reviews\n",
      "0      ---2PmXbF47D870stH1jqA            5.0            3\n",
      "2      --6PFZka7og6Khaw6oyjvQ            5.0            1\n",
      "3      --FtJYX8N228l3HPB7hkKQ            4.0            1\n",
      "4      --KsuCSkGGvDKTbdK9NvIg            4.0            1\n",
      "6      --XsxD0sMPKjWzApqy43XQ            5.0            1\n",
      "...                       ...            ...          ...\n",
      "38258  zyskmg9Cs_QF51TY7mb1sQ            5.0            1\n",
      "38263  zzFjNMND6ulzAYipvFlQAw            4.0            1\n",
      "38264  zzILpo4_UokEYhUAJ5uWvQ            4.0            1\n",
      "38265  zzOIjVi0YEOc3tSRD_RLsQ            4.0            1\n",
      "38267  zziJLt25YU6dp01sewR-IQ            3.8            5\n",
      "\n",
      "[29656 rows x 3 columns]\n"
>>>>>>> d7b66802502eb6a7ef89693cafafc747e918c711
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "pip install spacy"
=======
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "# Calculate average star rating for each user\n",
    "user_avg_rating = df.groupby('user_id')['stars'].mean().reset_index()\n",
    "user_avg_rating.columns = ['user_id', 'average_stars']  # Rename the column for clarity\n",
    "\n",
    "# Count number of reviews made by each user\n",
    "user_review_count = df['user_id'].value_counts().reset_index()\n",
    "user_review_count.columns = ['user_id', 'num_reviews']\n",
    "\n",
    "# Merge average rating and review count DataFrames\n",
    "user_stats = pd.merge(user_avg_rating, user_review_count, on='user_id')\n",
    "\n",
    "# Filter users with average rating less than 3 and at least one review\n",
    "users_with_low_rating = user_stats[(user_stats['average_stars'] >  3) & (user_stats['num_reviews'] > 0)]\n",
    "\n",
    "# Display the result\n",
    "print(users_with_low_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3520e55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id  num_reviews_midnight_to_5am\n",
      "0      ---2PmXbF47D870stH1jqA                            1\n",
      "1      --3WaS23LcIXtxyFULJHTA                            1\n",
      "2      --FtJYX8N228l3HPB7hkKQ                            1\n",
      "3      --qijw7qsKsG-v6rreDOAA                            1\n",
      "4      --u09WAjW741FdfkJXxNmg                            3\n",
      "...                       ...                          ...\n",
      "15384  zywyfATfP8SPY8JaYBraIg                            2\n",
      "15385  zzBhA0M7NNBMYoWj48h53A                            1\n",
      "15386  zzFjNMND6ulzAYipvFlQAw                            1\n",
      "15387  zzT0pSbiaNAPL171kwnvjA                            1\n",
      "15388  zziJLt25YU6dp01sewR-IQ                            2\n",
      "\n",
      "[15389 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "\n",
    "# Convert 'time' column to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S')\n",
    "\n",
    "# Filter reviews between 00:00 and 5:00\n",
    "reviews_between_midnight_and_5am = df[(df['time'].dt.hour >= 0) & (df['time'].dt.hour < 5)]\n",
    "\n",
    "# Group by 'user_id' and count the number of reviews\n",
    "user_reviews_midnight_to_5am = reviews_between_midnight_and_5am.groupby('user_id').size().reset_index(name='num_reviews_midnight_to_5am')\n",
    "\n",
    "# Display the result\n",
    "print(user_reviews_midnight_to_5am)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfde728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     user_id  num_low_rated_reviews_midnight_to_5am\n",
      "0     -0aZWYi2YicFaLxTru96nA                                      1\n",
      "1     -3s52C4zL_DHRK0ULG6qtg                                      3\n",
      "2     -3zMbAzCc74PstMHQHnXBA                                      1\n",
      "3     -4RbxLJlFZlu-KRuUiiGLw                                      1\n",
      "4     -7q3rd8_NeMXnMGySFFpEg                                      1\n",
      "...                      ...                                    ...\n",
      "3203  zx2NykkcJd1vdOgoS_ZhjQ                                      1\n",
      "3204  zxdgI8d0g6cX4mAl5_ALFA                                      1\n",
      "3205  zywyfATfP8SPY8JaYBraIg                                      2\n",
      "3206  zzBhA0M7NNBMYoWj48h53A                                      1\n",
      "3207  zzT0pSbiaNAPL171kwnvjA                                      1\n",
      "\n",
      "[3208 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "\n",
    "# Convert 'time' column to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S')\n",
    "\n",
    "# Filter reviews with a rating less than 3 and with time between 00:00 and 05:00\n",
    "low_rated_reviews_midnight_to_5am = df[(df['stars'] < 3) & (df['time'].dt.hour >= 0) & (df['time'].dt.hour < 5)]\n",
    "\n",
    "# Group by 'user_id' and count the number of low-rated reviews for each user\n",
    "user_low_rated_review_counts_midnight_to_5am = low_rated_reviews_midnight_to_5am.groupby('user_id').size().reset_index(name='num_low_rated_reviews_midnight_to_5am')\n",
    "\n",
    "# Display the result\n",
    "print(user_low_rated_review_counts_midnight_to_5am)\n"
>>>>>>> d7b66802502eb6a7ef89693cafafc747e918c711
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD
   "id": "5186e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text  \\\n",
      "0       Remarkable food with beach access for the whol...   \n",
      "1       I loved everything about this lovely train sta...   \n",
      "2       The Praline Connection makes a mean po' boy.  ...   \n",
      "3       We walked over to Tennessee Brew Works, one of...   \n",
      "4       Logan Circle, also known as Logan Square, is a...   \n",
      "...                                                   ...   \n",
      "103390  What an awesome place with a great vibe. Very ...   \n",
      "103391  This is an old style café with a lot of menu c...   \n",
      "103392  Great little coffee shop. Some nice pastries r...   \n",
      "103393  This is a fun place for awesome drinks and awe...   \n",
      "103394  Great little coffee shop. Some nice pastries r...   \n",
      "\n",
      "                                           tokenized_text  \n",
      "0       [Remarkable, food, with, beach, access, for, t...  \n",
      "1       [I, loved, everything, about, this, lovely, tr...  \n",
      "2       [The, Praline, Connection, makes, a, mean, po,...  \n",
      "3       [We, walked, over, to, Tennessee, Brew, Works,...  \n",
      "4       [Logan, Circle, ,, also, known, as, Logan, Squ...  \n",
      "...                                                   ...  \n",
      "103390  [What, an, awesome, place, with, a, great, vib...  \n",
      "103391  [This, is, an, old, style, café, with, a, lot,...  \n",
      "103392  [Great, little, coffee, shop, ., Some, nice, p...  \n",
      "103393  [This, is, a, fun, place, for, awesome, drinks...  \n",
      "103394  [Great, little, coffee, shop, ., Some, nice, p...  \n",
      "\n",
      "[103395 rows x 2 columns]\n"
=======
   "id": "ec3cd498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     user_id  num_low_rated_reviews_remaining_time\n",
      "0     --U6F4iI3ABK6IVCCgYc-g                                     1\n",
      "1     --bcBB892GN4ycJbGli0MQ                                     1\n",
      "2     --ccVMj2PN6Z9qtdOdlung                                     1\n",
      "3     --u09WAjW741FdfkJXxNmg                                     1\n",
      "4     -2ccuXJJIQmaXKQ9krmRfw                                     1\n",
      "...                      ...                                   ...\n",
      "7673  zySfwbIHPNhLR8-JiqGdWA                                     1\n",
      "7674  zywyfATfP8SPY8JaYBraIg                                     1\n",
      "7675  zz-2jnao6J1enCmzs7FBoA                                     1\n",
      "7676  zz0xCxZhHIceqSIlKIcj9A                                     1\n",
      "7677  zziJLt25YU6dp01sewR-IQ                                     1\n",
      "\n",
      "[7678 rows x 2 columns]\n"
>>>>>>> d7b66802502eb6a7ef89693cafafc747e918c711
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "df = pd.read_csv('btp.csv')\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "df['tokenized_text'] = df['text'].apply(tokenize_text)\n",
    "print(df[['text', 'tokenized_text']])\n"
=======
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "\n",
    "# Convert 'time' column to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S')\n",
    "\n",
    "# Filter reviews with a rating less than 3 and with time outside of 00:00 to 05:00\n",
    "low_rated_reviews_remaining_time = df[(df['stars'] < 3) & ((df['time'].dt.hour >= 5) | (df['time'].dt.hour < 0))]\n",
    "\n",
    "# Group by 'user_id' and count the number of low-rated reviews for each user\n",
    "user_low_rated_review_counts_remaining_time = low_rated_reviews_remaining_time.groupby('user_id').size().reset_index(name='num_low_rated_reviews_remaining_time')\n",
    "\n",
    "# Display the result\n",
    "print(user_low_rated_review_counts_remaining_time)\n"
>>>>>>> d7b66802502eb6a7ef89693cafafc747e918c711
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "f33920e9",
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 5,
   "id": "e8467d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id  num_high_rated_reviews_remaining_time\n",
      "0      ---2PmXbF47D870stH1jqA                                      2\n",
      "1      --6PFZka7og6Khaw6oyjvQ                                      1\n",
      "2      --KsuCSkGGvDKTbdK9NvIg                                      1\n",
      "3      --U6F4iI3ABK6IVCCgYc-g                                      1\n",
      "4      --XsxD0sMPKjWzApqy43XQ                                      1\n",
      "...                       ...                                    ...\n",
      "28043  zz-2jnao6J1enCmzs7FBoA                                      2\n",
      "28044  zzBhA0M7NNBMYoWj48h53A                                      1\n",
      "28045  zzILpo4_UokEYhUAJ5uWvQ                                      1\n",
      "28046  zzOIjVi0YEOc3tSRD_RLsQ                                      1\n",
      "28047  zziJLt25YU6dp01sewR-IQ                                      2\n",
      "\n",
      "[28048 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "\n",
    "# Convert 'time' column to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S')\n",
    "\n",
    "# Filter reviews with a rating greater than or equal to 3 and with time outside of 00:00 to 05:00\n",
    "high_rated_reviews_remaining_time = df[(df['stars'] >= 3) & ((df['time'].dt.hour >= 5) | (df['time'].dt.hour < 0))]\n",
    "\n",
    "# Group by 'user_id' and count the number of high-rated reviews for each user\n",
    "user_high_rated_review_counts_remaining_time = high_rated_reviews_remaining_time.groupby('user_id').size().reset_index(name='num_high_rated_reviews_remaining_time')\n",
    "\n",
    "# Display the result\n",
    "print(user_high_rated_review_counts_remaining_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a34a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id   useful  review_id  useful_ratio  \\\n",
      "11094  Hi10sGSZNxQH3NLyWSZ1oA  3300736         16      206296.0   \n",
      "27063  hWDybu_KvYLSdEFzGrniTw  5538848         32      173089.0   \n",
      "6877   AbMjnKOwg736fcIu8apuyQ   372933          3      124311.0   \n",
      "11131  Hm0diOkWwpo9zotlJlqMUQ   319575          3      106525.0   \n",
      "29781  m07sy7eLtOjVdZ8oN9JKag   220584          3       73528.0   \n",
      "...                       ...      ...        ...           ...   \n",
      "34881  uSNUUBPM3rXicWJU3uAlyg        0          1           0.0   \n",
      "9697   FLNOFeUIQupoopjezRB20g        0          1           0.0   \n",
      "8608   DWj14_QDxxw643UhPA-x1g        0          1           0.0   \n",
      "23782  bydK1xQQOKHrWwI7fY_sTg        0          1           0.0   \n",
      "24613  dOHyGVAXVAsMT34RX1KavA        0          1           0.0   \n",
      "\n",
      "       scaled_useful_ratio  \n",
      "11094             1.000000  \n",
      "27063             0.839032  \n",
      "6877              0.602586  \n",
      "11131             0.516370  \n",
      "29781             0.356420  \n",
      "...                    ...  \n",
      "34881             0.000000  \n",
      "9697              0.000000  \n",
      "8608              0.000000  \n",
      "23782             0.000000  \n",
      "24613             0.000000  \n",
      "\n",
      "[38268 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "\n",
    "# Group by 'user_id' and calculate the sum of 'useful' and the count of rows for each user\n",
    "user_grouped = df.groupby('user_id').agg({'useful': 'sum', 'review_id': 'count'}).reset_index()\n",
    "\n",
    "# Calculate the ratio of useful reviews to the total number of reviews for each user\n",
    "user_grouped['useful_ratio'] = user_grouped['useful'] / user_grouped['review_id']\n",
    "\n",
    "# Scale the ratio to the range of 0 to 1\n",
    "min_ratio = user_grouped['useful_ratio'].min()\n",
    "max_ratio = user_grouped['useful_ratio'].max()\n",
    "user_grouped['scaled_useful_ratio'] = (user_grouped['useful_ratio'] - min_ratio) / (max_ratio - min_ratio)\n",
    "\n",
    "# Sort the users based on the scaled ratio in descending order\n",
    "user_sorted = user_grouped.sort_values(by='scaled_useful_ratio', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(user_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "467d01e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id  num_short_reviews\n",
      "0      ---2PmXbF47D870stH1jqA                  1\n",
      "1      --KsuCSkGGvDKTbdK9NvIg                  1\n",
      "2      --ZNfWKj1VyVElRx6-g1fg                  1\n",
      "3      --ihyTzmVu69e61bTn0_mA                  1\n",
      "4      --mm7mLpnDS3mNlwuAdbtA                  1\n",
      "...                       ...                ...\n",
      "14435  zywyfATfP8SPY8JaYBraIg                  1\n",
      "14436  zz0xCxZhHIceqSIlKIcj9A                  1\n",
      "14437  zzBhA0M7NNBMYoWj48h53A                  1\n",
      "14438  zzFjNMND6ulzAYipvFlQAw                  1\n",
      "14439  zziJLt25YU6dp01sewR-IQ                  3\n",
      "\n",
      "[14440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('btp.csv')\n",
    "\n",
    "# Calculate the length of each review in terms of words\n",
    "df['review_length'] = df['text'].str.split().str.len()\n",
    "\n",
    "# Group by 'user_id' and count the number of reviews with length less than 50 words for each user\n",
    "user_review_length_counts = df[df['review_length'] < 50].groupby('user_id').size().reset_index(name='num_short_reviews')\n",
    "\n",
    "# Filter users with number of short reviews less than 50 words\n",
    "users_with_short_reviews = user_review_length_counts[user_review_length_counts['num_short_reviews'] > 0]\n",
    "\n",
    "# Display the result\n",
    "print(users_with_short_reviews)\n"
   ]
>>>>>>> d7b66802502eb6a7ef89693cafafc747e918c711
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
